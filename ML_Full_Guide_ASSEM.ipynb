{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# دليل متكامل في **Machine Learning** — شرح تفصيلي بالعربي\n",
        "مرحباً يا **ASSEM** 👋\n",
        "\n",
        "هذا ملف **Jupyter Notebook** متكامل يشرح كل ما تحدثنا عنه — نظري + عملي + أمثلة قابلة للتشغيل خطوة بخطوة. يتضمن:\n",
        "- مفاهيم أساسية (Features, Labels, Overfitting...)\n",
        "- تحضير البيانات (تنظيف، ترميز، موازنة، تقليل أبعاد)\n",
        "- التعلم الموجّه (انحدار وتصنيف) مع خوارزميات متعددة\n",
        "- التعلم غير الموجّه (تجميع وتقليل أبعاد)\n",
        "- التعلم بالتعزيز (مقدمة وQ-Learning)\n",
        "- مقدمة للشبكات العصبية (مثال عملي بـ Keras)\n",
        "- تقييم النماذج، ضبط المعاملات، Pipelines، ونصائح عملية\n",
        "\n",
        "## كيفية الاستخدام\n",
        "1. افتح هذا الملف في Jupyter Notebook أو JupyterLab.\n",
        "2. شغّل الخلايا الخلوية (Cell) واحدة تلو الأخرى.\n",
        "3. يمكنك تعديل البيانات أو المسارات لتستخدم ملفاتك المحلية.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## المتطلبات المسبقة\n",
        "- Python 3.8+، وبيئة Jupyter\n",
        "- مكتبات مقترحة: `numpy`, `pandas`, `matplotlib`, `seaborn`, `scikit-learn`, `tensorflow` (اختياري)، `joblib`\n",
        "\n",
        "يمكن تثبيت المكتبات (إن لم تكن مثبتة) عبر:\n",
        "```bash\n",
        "pip install numpy pandas matplotlib seaborn scikit-learn tensorflow joblib\n",
        "```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# إعداد الاستيرادات الأساسية\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, mean_absolute_error, r2_score,\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, roc_auc_score, roc_curve, silhouette_score\n",
        ")\n",
        "\n",
        "import joblib\n",
        "\n",
        "print('Libraries imported — ready to run examples')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## قسم 1 — تحضير البيانات (Data Preparation)\n",
        "\n",
        "هنا سنتعلم خطوات التحضير الأساسية: فحص البيانات، تنظيفها، تعامُل مع القيم المفقودة، الترميز، والتقييس.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# مثال: تحميل بيانات جاهزة (Iris) والتعرّف عليها\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris(as_frame=True)\n",
        "df = iris.frame\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### فحص سريع (EDA)\n",
        "- `df.info()` لمعرفة أنواع الأعمدة والقيم المفقودة\n",
        "- `df.describe()` للإحصاءات الوصفية\n",
        "- رسومات: histogram, pairplot, heatmap للـ correlation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.info()\n",
        "df.describe()\n",
        "\n",
        "# رسم مصفوفة الارتباط\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(df.corr(), annot=True, fmt='.2f')\n",
        "plt.title('Correlation matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### التعامل مع القيم المفقودة\n",
        "- حذف الصفوف (`dropna`) أو تعبئتها (`fillna`) بالقيمة الوسطى/المتوسطة أو نموذج توقع.\n",
        "- أمثلة: `df.fillna(df.median())`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# مثال افتراضي: تعبئة القيم المفقودة بالوسيط\n",
        "df_missing = df.copy()\n",
        "df_missing.iloc[0,0] = np.nan\n",
        "print('قبل عدد القيم المفقودة:', df_missing.isna().sum().sum())\n",
        "df_missing = df_missing.fillna(df_missing.median())\n",
        "print('بعد التعبئة عدد القيم المفقودة:', df_missing.isna().sum().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### الترميز (Encoding) للمتغيرات النصية\n",
        "- `LabelEncoder` للمتغيرات الترتيبية البسيطة\n",
        "- `OneHotEncoder` للفئات غير المرتبة\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# مثال بسيط على OneHot (لو كانت لدينا فئة)\n",
        "df_cat = pd.DataFrame({'color': ['red', 'blue', 'green', 'red']})\n",
        "pd.get_dummies(df_cat, columns=['color'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### التقييس (Scaling)\n",
        "- `StandardScaler` يجعل البيانات لها وسط 0 وانحراف معياري 1.\n",
        "- `MinMaxScaler` يحول القيم إلى نطاق [0,1].\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scaler = StandardScaler()\n",
        "X = df.drop(columns=['target'])\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "pd.DataFrame(X_scaled, columns=X.columns).head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## قسم 2 — Supervised Learning (التعلم الموجّه)\n",
        "سنتناول: الانحدار (Regression) والتصنيف (Classification) مع أمثلة وكود التقييم.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Linear Regression (انحدار خطي)\n",
        "فكرة بسيطة: نمثل العلاقة على شكل خط `y = wx + b` ونقلل مربع الفرق (MSE).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# مثال عملي: انحدار خطي على بيانات مولدة\n",
        "from sklearn.datasets import make_regression\n",
        "X_reg, y_reg = make_regression(n_samples=200, n_features=1, noise=15, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)\n",
        "print('MSE:', mean_squared_error(y_test, y_pred))\n",
        "print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
        "print('R2:', r2_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Logistic Regression (التصنيف الثنائي)\n",
        "تستخدم دالة Sigmoid لتحويل المخرجات لقيم بين 0 و 1 ثم عتبة لتصنيفها.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "pipe = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=5000))])\n",
        "pipe.fit(X_train, y_train)\n",
        "y_pred = pipe.predict(X_test)\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred))\n",
        "print('Recall:', recall_score(y_test, y_pred))\n",
        "print('F1:', f1_score(y_test, y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion matrix:\\n', cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Decision Tree و Random Forest\n",
        "- Decision Tree يعمِّل القرارات بشكل هرمي.\n",
        "- Random Forest هو Ensemble من عدة أشجار يقلّل الـ overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "print('RF Accuracy:', accuracy_score(y_test, y_pred))\n",
        "feat_imp = pd.Series(rf.feature_importances_, index=data.feature_names).sort_values(ascending=False)\n",
        "print('Top features:\\n', feat_imp.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Support Vector Machine و KNN\n",
        "- SVM يبحث عن أفضل Hyperplane لفصل الأصناف.\n",
        "- KNN يعتمد على أقرب الجيران لاتخاذ القرار.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "svc = SVC()\n",
        "svc.fit(X_train, y_train)\n",
        "print('SVM Accuracy:', svc.score(X_test, y_test))\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "print('KNN Accuracy:', knn.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 تقييم النموذج: مقاييس مهمة\n",
        "- Regression: MSE, RMSE, MAE, R2\n",
        "- Classification: Accuracy, Precision, Recall, F1, ROC-AUC, Confusion Matrix\n",
        "\n",
        "استخدم دائماً أكثر من مقياس واحد للحكم على أداء النموذج."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.6 Overfitting vs Underfitting\n",
        "- **Overfitting**: أداء ممتاز على التدريب وضعيف على الاختبار. العلاج: تبسيط النموذج، regularization، جمع بيانات.\n",
        "- **Underfitting**: النموذج بسيط جداً ولا يلتقط الأنماط. العلاج: استخدام نموذج أكثر تعقيداً أو ميزات أفضل.\n",
        "\n",
        "مبدأ **Bias-Variance Tradeoff** يشرح هذا التوازن."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.7 ضبط الـ Hyperparameters\n",
        "- استخدم `GridSearchCV` أو `RandomizedSearchCV` لتجربة تركيبات المعاملات.\n",
        "```python\n",
        "param_grid = {'clf__C': [0.01, 0.1, 1, 10], 'clf__penalty': ['l2']}\n",
        "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "print(grid.best_params_, grid.best_score_)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## قسم 3 — Unsupervised Learning (التعلم غير الموجّه)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 K-Means Clustering\n",
        "- اختر عدد المجموعات `k` باستخدام Elbow method أو Silhouette score.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "X_blob, _ = make_blobs(n_samples=300, centers=4, cluster_std=0.6, random_state=42)\n",
        "inertia = []\n",
        "K_range = range(1,10)\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X_blob)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "plt.plot(K_range, inertia, marker='o')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Elbow Method')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 PCA (تقليل الأبعاد)\n",
        "- PCA يحسب المركبات الأساسية التي تشرح أكبر قدر من التباين.\n",
        "```python\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_blob)\n",
        "print(pca.explained_variance_ratio_)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_blob)\n",
        "plt.scatter(X_pca[:,0], X_pca[:,1])\n",
        "plt.title('PCA projection')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## قسم 4 — Reinforcement Learning (التعلم بالتعزيز)\n",
        "مقدمة بسيطة ومثال على Q-Learning (مذكور في Notebook السابق أيضاً).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Q-Learning مبسّط\n",
        "states = [0,1,2,3,4]\n",
        "actions = [0,1]  # 0=left, 1=right\n",
        "Q = np.zeros((len(states), len(actions)))\n",
        "alpha = 0.1\n",
        "gamma = 0.9\n",
        "episodes = 200\n",
        "for ep in range(episodes):\n",
        "    state = 0\n",
        "    while state < 4:\n",
        "        action = np.random.choice([0,1])\n",
        "        next_state = state + 1 if action==1 else max(0, state-1)\n",
        "        reward = 1 if next_state==4 else 0\n",
        "        Q[state, action] += alpha * (reward + gamma * np.max(Q[next_state]) - Q[state, action])\n",
        "        state = next_state\n",
        "Q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## قسم 5 — مقدمة للشبكات العصبية (Neural Networks)\n",
        "سأقدّم مثال بسيط باستخدام `tensorflow.keras` لإنشاء MLP (شبكة متعدّدة الطبقات) لتصنيف بيانات سرطان الثدي.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Dense, Dropout\n",
        "    # إعداد البيانات نفسها المستخدمة أعلاه\n",
        "    X_train_s = StandardScaler().fit_transform(X_train)\n",
        "    X_test_s = StandardScaler().fit_transform(X_test)\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(X_train_s.shape[1],)),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    print('Keras model created (train separately if you want to run).')\n",
        "except Exception as e:\n",
        "    print('TensorFlow not available or another issue — model cell left as example.\\n', e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## قسم 6 — نشر النماذج (Deployment) وجوانب عملية\n",
        "- حفظ النموذج: `joblib.dump(model, 'model.joblib')`\n",
        "- استخدام `Pipeline` لتجميع خطوات التحضير + النموذج حتى يسهل النشر.\n",
        "- أفكار للنشر: Flask/FastAPI لخدمة نموذج عبر REST، أو تحويل نموذج TensorFlow إلى SavedModel.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# مثال: حفظ نموذج RandomForest\n",
        "joblib.dump(rf, '/mnt/data/rf_breast_cancer.joblib')\n",
        "print('Model saved to /mnt/data/rf_breast_cancer.joblib')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## قسم 7 — نصائح عملية ونهائية\n",
        "- ابدأ دائماً بـ EDA وVisualization.\n",
        "- قسّم البيانات جيداً (train/validation/test) أو استخدم cross-validation.\n",
        "- حافظ على Reproducibility (random_state, seeds).\n",
        "- سجل تجاربك (مثل MLflow أو حتى ملف CSV بسيط) لتتبع الأداء.\n",
        "- جرّب طرق Explainability (SHAP, LIME) إذا كنت بحاجة لتفسير قرارات النموذج.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## تمارين واقتراحات تطبيقية\n",
        "1. تطبيق الانحدار الخطي على مجموعة بيانات أسعار المنازل (California Housing).\n",
        "2. بناء نموذج تصنيف (RandomForest) لمجموعة بيانات Titanic أو Breast Cancer.\n",
        "3. تجربة K-Means على بيانات العملاء ومحاولة تفسير المجموعات.\n",
        "4. تنفيذ GridSearchCV للعثور على أفضل hyperparameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### انتهى الدليل — هل تريد نسخة PDF أو ملف Markdown قابل للطباعة؟\n",
        "أو هل تريد أن أعدّ نسخة مبسطة للـ Slides (عرض تقديمي) يمكنك مشاركته؟\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}