{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ø¯Ù„ÙŠÙ„ Ù…ØªÙƒØ§Ù…Ù„ ÙÙŠ **Machine Learning** â€” Ø´Ø±Ø­ ØªÙØµÙŠÙ„ÙŠ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ\n",
        "Ù…Ø±Ø­Ø¨Ø§Ù‹ ÙŠØ§ **ASSEM** ğŸ‘‹\n",
        "\n",
        "Ù‡Ø°Ø§ Ù…Ù„Ù **Jupyter Notebook** Ù…ØªÙƒØ§Ù…Ù„ ÙŠØ´Ø±Ø­ ÙƒÙ„ Ù…Ø§ ØªØ­Ø¯Ø«Ù†Ø§ Ø¹Ù†Ù‡ â€” Ù†Ø¸Ø±ÙŠ + Ø¹Ù…Ù„ÙŠ + Ø£Ù…Ø«Ù„Ø© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ´ØºÙŠÙ„ Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©. ÙŠØªØ¶Ù…Ù†:\n",
        "- Ù…ÙØ§Ù‡ÙŠÙ… Ø£Ø³Ø§Ø³ÙŠØ© (Features, Labels, Overfitting...)\n",
        "- ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (ØªÙ†Ø¸ÙŠÙØŒ ØªØ±Ù…ÙŠØ²ØŒ Ù…ÙˆØ§Ø²Ù†Ø©ØŒ ØªÙ‚Ù„ÙŠÙ„ Ø£Ø¨Ø¹Ø§Ø¯)\n",
        "- Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…ÙˆØ¬Ù‘Ù‡ (Ø§Ù†Ø­Ø¯Ø§Ø± ÙˆØªØµÙ†ÙŠÙ) Ù…Ø¹ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©\n",
        "- Ø§Ù„ØªØ¹Ù„Ù… ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬Ù‘Ù‡ (ØªØ¬Ù…ÙŠØ¹ ÙˆØªÙ‚Ù„ÙŠÙ„ Ø£Ø¨Ø¹Ø§Ø¯)\n",
        "- Ø§Ù„ØªØ¹Ù„Ù… Ø¨Ø§Ù„ØªØ¹Ø²ÙŠØ² (Ù…Ù‚Ø¯Ù…Ø© ÙˆQ-Learning)\n",
        "- Ù…Ù‚Ø¯Ù…Ø© Ù„Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ© (Ù…Ø«Ø§Ù„ Ø¹Ù…Ù„ÙŠ Ø¨Ù€ Keras)\n",
        "- ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ØŒ Ø¶Ø¨Ø· Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§ØªØŒ PipelinesØŒ ÙˆÙ†ØµØ§Ø¦Ø­ Ø¹Ù…Ù„ÙŠØ©\n",
        "\n",
        "## ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…\n",
        "1. Ø§ÙØªØ­ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù ÙÙŠ Jupyter Notebook Ø£Ùˆ JupyterLab.\n",
        "2. Ø´ØºÙ‘Ù„ Ø§Ù„Ø®Ù„Ø§ÙŠØ§ Ø§Ù„Ø®Ù„ÙˆÙŠØ© (Cell) ÙˆØ§Ø­Ø¯Ø© ØªÙ„Ùˆ Ø§Ù„Ø£Ø®Ø±Ù‰.\n",
        "3. ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ùˆ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ù„ØªØ³ØªØ®Ø¯Ù… Ù…Ù„ÙØ§ØªÙƒ Ø§Ù„Ù…Ø­Ù„ÙŠØ©.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø³Ø¨Ù‚Ø©\n",
        "- Python 3.8+ØŒ ÙˆØ¨ÙŠØ¦Ø© Jupyter\n",
        "- Ù…ÙƒØªØ¨Ø§Øª Ù…Ù‚ØªØ±Ø­Ø©: `numpy`, `pandas`, `matplotlib`, `seaborn`, `scikit-learn`, `tensorflow` (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)ØŒ `joblib`\n",
        "\n",
        "ÙŠÙ…ÙƒÙ† ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª (Ø¥Ù† Ù„Ù… ØªÙƒÙ† Ù…Ø«Ø¨ØªØ©) Ø¹Ø¨Ø±:\n",
        "```bash\n",
        "pip install numpy pandas matplotlib seaborn scikit-learn tensorflow joblib\n",
        "```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, mean_absolute_error, r2_score,\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, roc_auc_score, roc_curve, silhouette_score\n",
        ")\n",
        "\n",
        "import joblib\n",
        "\n",
        "print('Libraries imported â€” ready to run examples')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ù‚Ø³Ù… 1 â€” ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Data Preparation)\n",
        "\n",
        "Ù‡Ù†Ø§ Ø³Ù†ØªØ¹Ù„Ù… Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: ÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ØªÙ†Ø¸ÙŠÙÙ‡Ø§ØŒ ØªØ¹Ø§Ù…ÙÙ„ Ù…Ø¹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©ØŒ Ø§Ù„ØªØ±Ù…ÙŠØ²ØŒ ÙˆØ§Ù„ØªÙ‚ÙŠÙŠØ³.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ù…Ø«Ø§Ù„: ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø§Ù‡Ø²Ø© (Iris) ÙˆØ§Ù„ØªØ¹Ø±Ù‘Ù Ø¹Ù„ÙŠÙ‡Ø§\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris(as_frame=True)\n",
        "df = iris.frame\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ÙØ­Øµ Ø³Ø±ÙŠØ¹ (EDA)\n",
        "- `df.info()` Ù„Ù…Ø¹Ø±ÙØ© Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©\n",
        "- `df.describe()` Ù„Ù„Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©\n",
        "- Ø±Ø³ÙˆÙ…Ø§Øª: histogram, pairplot, heatmap Ù„Ù„Ù€ correlation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.info()\n",
        "df.describe()\n",
        "\n",
        "# Ø±Ø³Ù… Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(df.corr(), annot=True, fmt='.2f')\n",
        "plt.title('Correlation matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©\n",
        "- Ø­Ø°Ù Ø§Ù„ØµÙÙˆÙ (`dropna`) Ø£Ùˆ ØªØ¹Ø¨Ø¦ØªÙ‡Ø§ (`fillna`) Ø¨Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„ÙˆØ³Ø·Ù‰/Ø§Ù„Ù…ØªÙˆØ³Ø·Ø© Ø£Ùˆ Ù†Ù…ÙˆØ°Ø¬ ØªÙˆÙ‚Ø¹.\n",
        "- Ø£Ù…Ø«Ù„Ø©: `df.fillna(df.median())`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ù…Ø«Ø§Ù„ Ø§ÙØªØ±Ø§Ø¶ÙŠ: ØªØ¹Ø¨Ø¦Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø¨Ø§Ù„ÙˆØ³ÙŠØ·\n",
        "df_missing = df.copy()\n",
        "df_missing.iloc[0,0] = np.nan\n",
        "print('Ù‚Ø¨Ù„ Ø¹Ø¯Ø¯ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©:', df_missing.isna().sum().sum())\n",
        "df_missing = df_missing.fillna(df_missing.median())\n",
        "print('Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¹Ø¨Ø¦Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©:', df_missing.isna().sum().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ø§Ù„ØªØ±Ù…ÙŠØ² (Encoding) Ù„Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù†ØµÙŠØ©\n",
        "- `LabelEncoder` Ù„Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„ØªØ±ØªÙŠØ¨ÙŠØ© Ø§Ù„Ø¨Ø³ÙŠØ·Ø©\n",
        "- `OneHotEncoder` Ù„Ù„ÙØ¦Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø±ØªØ¨Ø©\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ù…Ø«Ø§Ù„ Ø¨Ø³ÙŠØ· Ø¹Ù„Ù‰ OneHot (Ù„Ùˆ ÙƒØ§Ù†Øª Ù„Ø¯ÙŠÙ†Ø§ ÙØ¦Ø©)\n",
        "df_cat = pd.DataFrame({'color': ['red', 'blue', 'green', 'red']})\n",
        "pd.get_dummies(df_cat, columns=['color'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ø§Ù„ØªÙ‚ÙŠÙŠØ³ (Scaling)\n",
        "- `StandardScaler` ÙŠØ¬Ø¹Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù‡Ø§ ÙˆØ³Ø· 0 ÙˆØ§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÙŠØ§Ø±ÙŠ 1.\n",
        "- `MinMaxScaler` ÙŠØ­ÙˆÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø¥Ù„Ù‰ Ù†Ø·Ø§Ù‚ [0,1].\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scaler = StandardScaler()\n",
        "X = df.drop(columns=['target'])\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "pd.DataFrame(X_scaled, columns=X.columns).head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ù‚Ø³Ù… 2 â€” Supervised Learning (Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…ÙˆØ¬Ù‘Ù‡)\n",
        "Ø³Ù†ØªÙ†Ø§ÙˆÙ„: Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± (Regression) ÙˆØ§Ù„ØªØµÙ†ÙŠÙ (Classification) Ù…Ø¹ Ø£Ù…Ø«Ù„Ø© ÙˆÙƒÙˆØ¯ Ø§Ù„ØªÙ‚ÙŠÙŠÙ….\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Linear Regression (Ø§Ù†Ø­Ø¯Ø§Ø± Ø®Ø·ÙŠ)\n",
        "ÙÙƒØ±Ø© Ø¨Ø³ÙŠØ·Ø©: Ù†Ù…Ø«Ù„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¹Ù„Ù‰ Ø´ÙƒÙ„ Ø®Ø· `y = wx + b` ÙˆÙ†Ù‚Ù„Ù„ Ù…Ø±Ø¨Ø¹ Ø§Ù„ÙØ±Ù‚ (MSE).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ù…Ø«Ø§Ù„ Ø¹Ù…Ù„ÙŠ: Ø§Ù†Ø­Ø¯Ø§Ø± Ø®Ø·ÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙˆÙ„Ø¯Ø©\n",
        "from sklearn.datasets import make_regression\n",
        "X_reg, y_reg = make_regression(n_samples=200, n_features=1, noise=15, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)\n",
        "print('MSE:', mean_squared_error(y_test, y_pred))\n",
        "print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
        "print('R2:', r2_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Logistic Regression (Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠ)\n",
        "ØªØ³ØªØ®Ø¯Ù… Ø¯Ø§Ù„Ø© Sigmoid Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ù„Ù‚ÙŠÙ… Ø¨ÙŠÙ† 0 Ùˆ 1 Ø«Ù… Ø¹ØªØ¨Ø© Ù„ØªØµÙ†ÙŠÙÙ‡Ø§.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "pipe = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=5000))])\n",
        "pipe.fit(X_train, y_train)\n",
        "y_pred = pipe.predict(X_test)\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred))\n",
        "print('Recall:', recall_score(y_test, y_pred))\n",
        "print('F1:', f1_score(y_test, y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion matrix:\\n', cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Decision Tree Ùˆ Random Forest\n",
        "- Decision Tree ÙŠØ¹Ù…ÙÙ‘Ù„ Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª Ø¨Ø´ÙƒÙ„ Ù‡Ø±Ù…ÙŠ.\n",
        "- Random Forest Ù‡Ùˆ Ensemble Ù…Ù† Ø¹Ø¯Ø© Ø£Ø´Ø¬Ø§Ø± ÙŠÙ‚Ù„Ù‘Ù„ Ø§Ù„Ù€ overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "print('RF Accuracy:', accuracy_score(y_test, y_pred))\n",
        "feat_imp = pd.Series(rf.feature_importances_, index=data.feature_names).sort_values(ascending=False)\n",
        "print('Top features:\\n', feat_imp.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Support Vector Machine Ùˆ KNN\n",
        "- SVM ÙŠØ¨Ø­Ø« Ø¹Ù† Ø£ÙØ¶Ù„ Hyperplane Ù„ÙØµÙ„ Ø§Ù„Ø£ØµÙ†Ø§Ù.\n",
        "- KNN ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø£Ù‚Ø±Ø¨ Ø§Ù„Ø¬ÙŠØ±Ø§Ù† Ù„Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "svc = SVC()\n",
        "svc.fit(X_train, y_train)\n",
        "print('SVM Accuracy:', svc.score(X_test, y_test))\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "print('KNN Accuracy:', knn.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: Ù…Ù‚Ø§ÙŠÙŠØ³ Ù…Ù‡Ù…Ø©\n",
        "- Regression: MSE, RMSE, MAE, R2\n",
        "- Classification: Accuracy, Precision, Recall, F1, ROC-AUC, Confusion Matrix\n",
        "\n",
        "Ø§Ø³ØªØ®Ø¯Ù… Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø£ÙƒØ«Ø± Ù…Ù† Ù…Ù‚ÙŠØ§Ø³ ÙˆØ§Ø­Ø¯ Ù„Ù„Ø­ÙƒÙ… Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.6 Overfitting vs Underfitting\n",
        "- **Overfitting**: Ø£Ø¯Ø§Ø¡ Ù…Ù…ØªØ§Ø² Ø¹Ù„Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ¶Ø¹ÙŠÙ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±. Ø§Ù„Ø¹Ù„Ø§Ø¬: ØªØ¨Ø³ÙŠØ· Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ regularizationØŒ Ø¬Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª.\n",
        "- **Underfitting**: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø³ÙŠØ· Ø¬Ø¯Ø§Ù‹ ÙˆÙ„Ø§ ÙŠÙ„ØªÙ‚Ø· Ø§Ù„Ø£Ù†Ù…Ø§Ø·. Ø§Ù„Ø¹Ù„Ø§Ø¬: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø£ÙƒØ«Ø± ØªØ¹Ù‚ÙŠØ¯Ø§Ù‹ Ø£Ùˆ Ù…ÙŠØ²Ø§Øª Ø£ÙØ¶Ù„.\n",
        "\n",
        "Ù…Ø¨Ø¯Ø£ **Bias-Variance Tradeoff** ÙŠØ´Ø±Ø­ Ù‡Ø°Ø§ Ø§Ù„ØªÙˆØ§Ø²Ù†."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.7 Ø¶Ø¨Ø· Ø§Ù„Ù€ Hyperparameters\n",
        "- Ø§Ø³ØªØ®Ø¯Ù… `GridSearchCV` Ø£Ùˆ `RandomizedSearchCV` Ù„ØªØ¬Ø±Ø¨Ø© ØªØ±ÙƒÙŠØ¨Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª.\n",
        "```python\n",
        "param_grid = {'clf__C': [0.01, 0.1, 1, 10], 'clf__penalty': ['l2']}\n",
        "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "print(grid.best_params_, grid.best_score_)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ù‚Ø³Ù… 3 â€” Unsupervised Learning (Ø§Ù„ØªØ¹Ù„Ù… ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬Ù‘Ù‡)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 K-Means Clustering\n",
        "- Ø§Ø®ØªØ± Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª `k` Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Elbow method Ø£Ùˆ Silhouette score.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "X_blob, _ = make_blobs(n_samples=300, centers=4, cluster_std=0.6, random_state=42)\n",
        "inertia = []\n",
        "K_range = range(1,10)\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X_blob)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "plt.plot(K_range, inertia, marker='o')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Elbow Method')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 PCA (ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯)\n",
        "- PCA ÙŠØ­Ø³Ø¨ Ø§Ù„Ù…Ø±ÙƒØ¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø§Ù„ØªÙŠ ØªØ´Ø±Ø­ Ø£ÙƒØ¨Ø± Ù‚Ø¯Ø± Ù…Ù† Ø§Ù„ØªØ¨Ø§ÙŠÙ†.\n",
        "```python\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_blob)\n",
        "print(pca.explained_variance_ratio_)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_blob)\n",
        "plt.scatter(X_pca[:,0], X_pca[:,1])\n",
        "plt.title('PCA projection')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ù‚Ø³Ù… 4 â€” Reinforcement Learning (Ø§Ù„ØªØ¹Ù„Ù… Ø¨Ø§Ù„ØªØ¹Ø²ÙŠØ²)\n",
        "Ù…Ù‚Ø¯Ù…Ø© Ø¨Ø³ÙŠØ·Ø© ÙˆÙ…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Q-Learning (Ù…Ø°ÙƒÙˆØ± ÙÙŠ Notebook Ø§Ù„Ø³Ø§Ø¨Ù‚ Ø£ÙŠØ¶Ø§Ù‹).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Q-Learning Ù…Ø¨Ø³Ù‘Ø·\n",
        "states = [0,1,2,3,4]\n",
        "actions = [0,1]  # 0=left, 1=right\n",
        "Q = np.zeros((len(states), len(actions)))\n",
        "alpha = 0.1\n",
        "gamma = 0.9\n",
        "episodes = 200\n",
        "for ep in range(episodes):\n",
        "    state = 0\n",
        "    while state < 4:\n",
        "        action = np.random.choice([0,1])\n",
        "        next_state = state + 1 if action==1 else max(0, state-1)\n",
        "        reward = 1 if next_state==4 else 0\n",
        "        Q[state, action] += alpha * (reward + gamma * np.max(Q[next_state]) - Q[state, action])\n",
        "        state = next_state\n",
        "Q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ù‚Ø³Ù… 5 â€” Ù…Ù‚Ø¯Ù…Ø© Ù„Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ© (Neural Networks)\n",
        "Ø³Ø£Ù‚Ø¯Ù‘Ù… Ù…Ø«Ø§Ù„ Ø¨Ø³ÙŠØ· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `tensorflow.keras` Ù„Ø¥Ù†Ø´Ø§Ø¡ MLP (Ø´Ø¨ÙƒØ© Ù…ØªØ¹Ø¯Ù‘Ø¯Ø© Ø§Ù„Ø·Ø¨Ù‚Ø§Øª) Ù„ØªØµÙ†ÙŠÙ Ø¨ÙŠØ§Ù†Ø§Øª Ø³Ø±Ø·Ø§Ù† Ø§Ù„Ø«Ø¯ÙŠ.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Dense, Dropout\n",
        "    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù†ÙØ³Ù‡Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ø£Ø¹Ù„Ø§Ù‡\n",
        "    X_train_s = StandardScaler().fit_transform(X_train)\n",
        "    X_test_s = StandardScaler().fit_transform(X_test)\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(X_train_s.shape[1],)),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    print('Keras model created (train separately if you want to run).')\n",
        "except Exception as e:\n",
        "    print('TensorFlow not available or another issue â€” model cell left as example.\\n', e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ù‚Ø³Ù… 6 â€” Ù†Ø´Ø± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (Deployment) ÙˆØ¬ÙˆØ§Ù†Ø¨ Ø¹Ù…Ù„ÙŠØ©\n",
        "- Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: `joblib.dump(model, 'model.joblib')`\n",
        "- Ø§Ø³ØªØ®Ø¯Ø§Ù… `Pipeline` Ù„ØªØ¬Ù…ÙŠØ¹ Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ­Ø¶ÙŠØ± + Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø­ØªÙ‰ ÙŠØ³Ù‡Ù„ Ø§Ù„Ù†Ø´Ø±.\n",
        "- Ø£ÙÙƒØ§Ø± Ù„Ù„Ù†Ø´Ø±: Flask/FastAPI Ù„Ø®Ø¯Ù…Ø© Ù†Ù…ÙˆØ°Ø¬ Ø¹Ø¨Ø± RESTØŒ Ø£Ùˆ ØªØ­ÙˆÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ TensorFlow Ø¥Ù„Ù‰ SavedModel.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ù…Ø«Ø§Ù„: Ø­ÙØ¸ Ù†Ù…ÙˆØ°Ø¬ RandomForest\n",
        "joblib.dump(rf, '/mnt/data/rf_breast_cancer.joblib')\n",
        "print('Model saved to /mnt/data/rf_breast_cancer.joblib')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ù‚Ø³Ù… 7 â€” Ù†ØµØ§Ø¦Ø­ Ø¹Ù…Ù„ÙŠØ© ÙˆÙ†Ù‡Ø§Ø¦ÙŠØ©\n",
        "- Ø§Ø¨Ø¯Ø£ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø¨Ù€ EDA ÙˆVisualization.\n",
        "- Ù‚Ø³Ù‘Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¬ÙŠØ¯Ø§Ù‹ (train/validation/test) Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… cross-validation.\n",
        "- Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Reproducibility (random_state, seeds).\n",
        "- Ø³Ø¬Ù„ ØªØ¬Ø§Ø±Ø¨Ùƒ (Ù…Ø«Ù„ MLflow Ø£Ùˆ Ø­ØªÙ‰ Ù…Ù„Ù CSV Ø¨Ø³ÙŠØ·) Ù„ØªØªØ¨Ø¹ Ø§Ù„Ø£Ø¯Ø§Ø¡.\n",
        "- Ø¬Ø±Ù‘Ø¨ Ø·Ø±Ù‚ Explainability (SHAP, LIME) Ø¥Ø°Ø§ ÙƒÙ†Øª Ø¨Ø­Ø§Ø¬Ø© Ù„ØªÙØ³ÙŠØ± Ù‚Ø±Ø§Ø±Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ØªÙ…Ø§Ø±ÙŠÙ† ÙˆØ§Ù‚ØªØ±Ø§Ø­Ø§Øª ØªØ·Ø¨ÙŠÙ‚ÙŠØ©\n",
        "1. ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù…Ù†Ø§Ø²Ù„ (California Housing).\n",
        "2. Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ ØªØµÙ†ÙŠÙ (RandomForest) Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Titanic Ø£Ùˆ Breast Cancer.\n",
        "3. ØªØ¬Ø±Ø¨Ø© K-Means Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ ÙˆÙ…Ø­Ø§ÙˆÙ„Ø© ØªÙØ³ÙŠØ± Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª.\n",
        "4. ØªÙ†ÙÙŠØ° GridSearchCV Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ hyperparameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø¯Ù„ÙŠÙ„ â€” Ù‡Ù„ ØªØ±ÙŠØ¯ Ù†Ø³Ø®Ø© PDF Ø£Ùˆ Ù…Ù„Ù Markdown Ù‚Ø§Ø¨Ù„ Ù„Ù„Ø·Ø¨Ø§Ø¹Ø©ØŸ\n",
        "Ø£Ùˆ Ù‡Ù„ ØªØ±ÙŠØ¯ Ø£Ù† Ø£Ø¹Ø¯Ù‘ Ù†Ø³Ø®Ø© Ù…Ø¨Ø³Ø·Ø© Ù„Ù„Ù€ Slides (Ø¹Ø±Ø¶ ØªÙ‚Ø¯ÙŠÙ…ÙŠ) ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø´Ø§Ø±ÙƒØªÙ‡ØŸ\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}